{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM의 정의\n",
    "LSTM(Long Short-Term Memory)은 순환 신경망(RNN)의 한 종료로, 시간에 따른 데이터의 장기적인 의존성(Long-term dependency)을 학습하는 데 뛰어난 능력을 가지고 있다. 일반 RNN은 시간이 지나면서 오래된 정보가 사라져 버리는 기울기 소실 문제(vanishing gradient problem)를 겪는데, LSTM은 이를 해결하기 위해 고안된 구조이다. \n",
    "\n",
    "#### 주요 특징:\n",
    "LSTM의 핵심은 **셀 상태(cell state)**와 이를 제어하는 **게이트(gates)**이다. 셀 상태는 정보를 계속 전달하며, 게이트는 정보를 추가하거나 제거할지를 결정하는 역할을 한다. \n",
    "\n",
    "- Input gate: 현재 입력 정보가 셀 상태에 얼마나 반영될지를 결정한다.\n",
    "- Forget gate: 셀 상태에서 이전 정보를 얼마나 잊을지를 결정한다.\n",
    "- Output gate: 다음 단계로 얼마나 많은 정보를 전달할 지 경정한다.\n",
    "\n",
    "이러한 구조를 통해 LSTM은 중요한 정보를 **장기적으로 기억**하고, 필요하지 않은 정보는 **제거**하여 효율적으로 학습할 수 있다. LSTM은 주로 시계열 데이터, 자연어 처리, 음성 인식 등 시간의존성이 강한 문제에 많이 사용된다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM의 응용 분야:\n",
    "1. 자연어 처리(NLP)\n",
    "- 텍스트 생성: LSTM을 활용해 이전 단어들의 흐름을 기반으로 다음 단어를 예측하는 방식으로 시, 소설 등 자연스러운 텍스트를 생성할 수 있다.\n",
    "- 감정 분석: 영화 리뷰나 SNS 데이터를 분석하여 긍정적 또는 부정적 감정을 분류하는 데 사용된다.  \n",
    "- 번역: LSTM 기반의 모델은 문장 구조를 이해하고, 한 언어에서 다른 언어로 번역하는데 많이 사용된다. 대표적인 예로 구글 번역(Google Translate)의 초기 모델이 LSTM을 사용했다.\n",
    "\n",
    "2. 시계열 데이터 분석\n",
    "- 주가 예측: LSTM은 주식 가격, 환율, 금리 거래량 등 금융 시계열 데이터를 분석하여 미래의 가격 변동을 예측하는 데 널리 사용되고 있다. 특히, LSTM은 과거 데이터에서 복잡한 패턴을 학습하고, 주가의 단기적 및 장기적 추세를 고려하여 보다 정확한 예측이 가능하다는 장점이 있다. \n",
    "- 기상 예측: 기상 데이터(온도, 강수랑, 습도, 기압)는 시간에 따라 변동하는 복잡한 시계열 데이터이다. LSTM은 과거의 기상 데이터를 학습하여 미래의 날씨를 예측하는 데 사용된다. 이러한 예측은 농업, 에너지 관리. 자연 재해 대비 등 여러 분야에서 중요한 역할을 한다.\n",
    "- 수요 예측 및 재고 관리: 전자 상거래 및 유통업체에서는 고객의 구매 패턴을 분석하고, 과거 판매 데이터를 학습하여 상품의 수요를 예측하고, 효율적인 재고관리를 위해 LSTM을 사용한다. 이를 통해 재고 부족 문제를 줄이고, 과잉 재고를 방지할 수 있다/\n",
    "- 의료 데이터 분석: 환자의 생체 신호 데이터(심박수, 혈압, 호흡 패턴 등)을 학습하여 질병의 발병가능성 예측이나 환자 상태 모니터링에 활용된다. 특히, 환자의 생체 신호는 시간에 따른 변화가 중요하기 때문에 LSTM이 효과적으로 적용될 수 있다.\n",
    "- 교통 예측 및 교통량 관리: 교통 데이터 분석에도 LSTM이 많이 사용된다. 예를 들어, 도로에서의 교통 흐름을 분석하고 혼잡도를 예측하거나, 대중교통의 운행 시간을 예측하여 사용자에게 정확한 정보를 제공하는 데 사용된다. 이를 통해, 교통 혼잡을 줄이고 효율적인 도로 관리를 도울 수 있다. \n",
    "\n",
    "3. 음성 인식\n",
    "- 음성-텍스트 변환: LSTM은 음성 데이터를 입력받아 이를 텍스트로 변환하는 데 사용된다. 음성은 시간적인 흐름이 중요한 데이터이기 때문에 LSTM의 시간 의존성 처리능력이 크게 기여한다.\n",
    "\n",
    "4. 영상 처리\n",
    "- 영상 프레임 예측: 영상 데이터를 다룰 때, 다음 프레임을 예측하거나 비디오 요약 등의 작업에 사용된다. 비디오 프레임은 연속적이기 때문에 LSTM이 각 프레임 간의 관계를 학습할 수 있다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM 성능 개선 모델들\n",
    "1. GRU (Gated Recurrent Unit)\n",
    "2. BiLSTM (Bidrectional LSTM)\n",
    "3. Stacked LSTM\n",
    "4. Attention Mechanism과 LSTM "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파이토치에서 LSTM 모델을 사용하는 기본적인 순서\n",
    "\n",
    "1. 데이터 준비\n",
    "- 텍스트 데이터나 시계열 데이터와 같은 시퀀스 데이터를 LSTM에 입력하려면, 데이터를 수치형 형태로 변환해야 한다.\n",
    "- 텍스트 데이터의 경우, 토큰화, 정수 인코딩, 패딩 등의 전처리 과정을 거쳐 데이터의 길이를 통일한다.\n",
    "    - 토큰화(Tokenization): 텍스트 데이터를 작은 단위로 나누는 작업. \n",
    "    - 정수 인코딩(Integer Encoding)\n",
    "    - 패딩(Padding): 모든 시퀀스 데이터의 길이를 동일하게 맞추기 위해 부족한 부분을 특정 값(보통 0)으로 채우는 작업.\n",
    "- 시계열 데이터의 경우, 정규화 및 특정 윈도우 크기를 설정해 시퀀스를 구성할 수 있다.\n",
    "\n",
    "2. 데이터셋 및 데이터로더 생성\n",
    "- 전처리된 데이터를 PyTorch의 Dataset 클래스를 상속받아 커스텀 데이터셋을 만든다.\n",
    "- 데이터셋 객체를 DataLoader로 감싸서 배치 단위로 데이터를 불러올 수 있도록 설정한다. 이때, batch_size와 shuffle 등을 설정한다.\n",
    "\n",
    "3. 모델 설계\n",
    "- PyTorch의 nn.Module 클래스를 상속받아 LSTM 모델 클래스를 정의한다.\n",
    "- LSTM 레이어는 nn.LSTM을 사용해 정의하며, 입력 차원(input_size), 은닉층 크기(hidden_size), LSTM 레이어의 수(num_layers)등을 지정한다.\n",
    "- LSTM의 출력값을 처리하기 위한 Fully Connected Layer(nn.Linear)를 추가해, 최종적으로 원하는 예측 결과를 출력할 수 있도록 설계한다.\n",
    "\n",
    "4. 손실 함수 및 옵티마이저 정의\n",
    "- 예측하고자 하는 문제에 따라 손실 함수(Loss Function)를 정의한다. 예를 들어, 회귀 문제의 경우 MSELoss, 분류 문제의 경우 CrossEntropyLoss등을 사용한다.\n",
    "- 옵티마이저로는 일반적으로 Adam이나 SGD를 사용하며, 모델의 학습 파라미터를 전달한다. \n",
    "\n",
    "5. 학습 및 모델 훈련\n",
    "- 학습을 위한 반복문을  설정한다. 기본적인 학습 절차는 다음과 같다:\n",
    "    1. DataLoader에서 배치를 불러온다.\n",
    "    2. 모델의 은닉 상태 초기화를 한다 (hidden state와 Cell state).\n",
    "    3. 데이터를 모델에 입력해 출력을 얻는다.\n",
    "    4. 출력과 실제 정답(레이블) 사이의 손실을 계산한다.\n",
    "    5. 옵티마이저의 기존 그래디언트 초기화 후, **역전파(Bacpropagation)**를 통해 그래디언트를 계산하고, 옵티마이저를 사용해 가중치를 업데이트 한다.\n",
    "\n",
    "6. 모델 평가\n",
    "- 학습이 완료되면, 평가 데이터셋을 통해 모델의 성능을 평가한다. 평가 시에는 모델을 평가 모드(model.eval())로 전환하고, 기울기 계산을 비활성화(torch.no_grad())하여 진행한다.\n",
    "- 정확도, RMSE 등 적절한 평가지표를 사용해 모델의 성능을 확인한다.\n",
    "\n",
    "7. 모델 저장 및 불러오기\n",
    "- 학습된 모델의 가중치를 저장하고 싶다면, torch.save()를 사용해 모델의 상태 딕셔너리(state_dict)를 저장한다. \n",
    "- 추후 모델을 불러올 때는 torch.load()와 model.load_state_dict()를 사용해 저장된 가중치를 불러온다.\n",
    "\n",
    "이 단계들을 따르면, PyTorch에서 LSTM 모델을 효율적으로 설계하고 사용할 수 있다. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
